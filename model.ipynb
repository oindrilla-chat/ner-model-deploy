{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy pre-trained SpaCy model using S2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we load a SpaCy based NLP model from S3 storage in-memory and draw predictions from it.\n",
    "\n",
    "We will then use [s2i](https://github.com/openshift/source-to-image) to operationalize this model and deploy it on OpenShift. This demo is based on Michael Clifford's ODSC demo [notebook](https://github.com/MichaelClifford/example-model-s2i-notebook/blob/master/model.ipynb) and is a specific use-case where we do not wish to train the model in notebook, rather load it in-memory and deploy it using s2i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first convention to follow is declaring your model's requirements as a list of lists in a variable called requirements. The s2i builder will use these to generate a `requirements.txt` file, which it will install while building an image. This step is optional, but it is necessary if your model will depend on any libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = [[\"spacy\", \"3.0.6\"], [\"boto3\", \"1.9.205\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The s2i build process will execute every cell in the notebook in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "# from dotenv import load_dotenv, find_dotenv #while running locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s2i will not have access to local directories, hence we will load the serialized SpaCy model from an S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the deployed application to be able to access these environment variables, we need to add them to the Build as Environment Variables. To add secure credentials to the build, you can first define secrets containing the key and value and import them into the build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(find_dotenv()) # use to locate credentials while running notebook locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = \"DH-SECURE-OCHATTER\"\n",
    "conn = boto3.client(service_name='s3',\n",
    "        aws_access_key_id= os.environ.get(\"s3-access-key\"),\n",
    "        aws_secret_access_key= os.environ.get(\"s3-secret-key\"),\n",
    "        endpoint_url='https://s3.upshift.redhat.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a SpaCy model, essentially the `nlp` object, we need to translate the contents into a byte like object by serializing it and then de-serialize it to load it to use it in our workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "The two main objects that are needed to effectively deserialize a SpaCy model are the model `config` and `nlp` object.\n",
    "The [SpaCy documentation](https://spacy.io/usage/saving-loading) lists the functions that can be used to serialize and desialize the objects for eg:\n",
    "```python\n",
    "config = nlp.config\n",
    "bytes_data = nlp.to_bytes()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already saved the `config` and `bytes_data` object onto S3 and in this notebook, we will load those from S3, re-create an `nlp` object and use to draw predictions from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_data = conn.get_object(Bucket=my_bucket, Key = 'model_deploy/model_in_bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx00000000000001a8c2612-0060c3951d-60765d10-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-length': '15831120',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'last-modified': 'Wed, 09 Jun 2021 19:22:31 GMT',\n",
       "   'x-rgw-object-type': 'Normal',\n",
       "   'etag': '\"1a191bd2ae70da9ba51204b2b31d7649-2\"',\n",
       "   'x-amz-request-id': 'tx00000000000001a8c2612-0060c3951d-60765d10-default',\n",
       "   'content-type': 'binary/octet-stream',\n",
       "   'date': 'Fri, 11 Jun 2021 16:53:49 GMT',\n",
       "   'connection': 'Keep-Alive',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'},\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2021, 6, 9, 19, 22, 31, tzinfo=tzutc()),\n",
       " 'ContentLength': 15831120,\n",
       " 'ETag': '\"1a191bd2ae70da9ba51204b2b31d7649-2\"',\n",
       " 'ContentType': 'binary/octet-stream',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.response.StreamingBody at 0x7f16ee85b550>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = conn.get_object(Bucket=my_bucket, Key = 'model_deploy/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx00000000000000f0a1c31-0060c3951d-652e5ed3-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-length': '5017',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'last-modified': 'Wed, 09 Jun 2021 19:22:31 GMT',\n",
       "   'x-rgw-object-type': 'Normal',\n",
       "   'etag': '\"fecc39263771ebd53d9bd453ff3da01a\"',\n",
       "   'x-amz-request-id': 'tx00000000000000f0a1c31-0060c3951d-652e5ed3-default',\n",
       "   'content-type': 'binary/octet-stream',\n",
       "   'date': 'Fri, 11 Jun 2021 16:53:49 GMT',\n",
       "   'connection': 'Keep-Alive',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'},\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2021, 6, 9, 19, 22, 31, tzinfo=tzutc()),\n",
       " 'ContentLength': 5017,\n",
       " 'ETag': '\"fecc39263771ebd53d9bd453ff3da01a\"',\n",
       " 'ContentType': 'binary/octet-stream',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.response.StreamingBody at 0x7f16ee85bf98>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bytes_data['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = config['Body'].read()\n",
    "json_content = json.loads(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will re-create the nlp object from the `config` and `bytes_data` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f16eeca5f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_cls = spacy.util.get_lang_class(json_content[\"nlp\"][\"lang\"])\n",
    "nlp = lang_cls.from_config(json_content)\n",
    "nlp.from_bytes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example prediction from the `nlp` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IBM', 'ORG')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"IBM is an organization\")\n",
    "[(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor and Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the trained model, you simply need to provide two functions:\n",
    "\n",
    "`predictor`, which will make a single prediction from a single sample, this can be customized as per the output you need to return from the model,\n",
    "and  \n",
    "`validator`, which will return True if a single sample is of the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(feed_text):\n",
    "    \n",
    "    doc = nlp(feed_text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`validator` is optional, but it will make your model service easier to use. If you don't provide one, your model service will accept any input, which will likely lead to confusing error messages (i.e., crashes somewhere in the predictor) if your model service is called with bogus input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validator(x):\n",
    "    \n",
    "    return type(x) == str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
